#!/bin/bash -l
#PBS -N r_filter_split_json
#PBS -l ncpus=32
#PBS -l mem=64GB
#PBS -l walltime=24:00:00

HOME_DIR=/home/suzor
WORK_DIR=/work/platforms

module load parallel
module load jq

cd $WORK_DIR/reddit
find . -name "*json*" -size +2G -print0 | xargs -0 -P 18 -I {} sh -c "cat {} | jq -cRr '. as \$line | try fromjson catch stderr | {created_utc,id,link
_id,parent_id,author,retrieved_on,subreddit_id,subreddit,subreddit_type,quarantined,author_created_utc,author_fullname,body}' | split -l 100000 -d --s
uffix-length=6 - {}" 1>/dev/null 2> failed

echo Loading module python
module load python/3.9.6-gcccore-11.2.0

source $HOME_DIR/src/venv396/bin/activate

echo uploading

mkdir -p $WORK_DIR/reddit_fs
find . -name "*json0*" -size -2G -exec mv {} $WORK_DIR/reddit_fs/ \;
$HOME_DIR/google-cloud-sdk/bin/gsutil -m mv -n $WORK_DIR/reddit_fs/*json* gs://dmrc-platforms/reddit_author/


-------------------------------

# check malformed json
find . -type f -size -2G -print0 | xargs -0 -P 16 -I {} sh -c "cat {} | jq type && echo {} OK || echo {} invalid."
 or:
 cat {} | jq -cRr "(fromjson?|.)//error(.)" | tee -a {} 1< /dev/null


# extract good rows:
find . -type f -size -2G -print0 | xargs -0 -P 16 -I {} sh -c "cat {} | jq -c -R -r '(fromjson? | .)//error(.)' | tee -a ../reddit_fs_ok/{}" 1>/dev/null 2>~/reddit_fs_malformed/errors.txt

# From a set of large files:
find . -name "RC_2021-01.json*" -size -2G -print0 | xargs -0 -P 16 -I {} sh -c "cat {} | jq -cRr '(fromjson? | {created_utc,id,link_id,parent_id,retrieved_on,subreddit_id,subreddit,subreddit_type,quarantined,author_created_utc,author,author_fullname,body})//error(.)' | split -l 10000 - {}.valid.split" 2>~/errors.txt
